---
title: EES2019 Stacking Process 
subtitle: Synthetic Variables Evaluation (Pt.2)
author: Giuseppe Carteny
date: 24.10.2021 
toc: true
output: 
  bookdown::pdf_document2:
    includes:
      in_header: First_steps_header.tex
urlcolor: RedOrange
--- 

```{r echo=FALSE, warning=FALSE, message=FALSE}

# Admin # ==============================================================================================

want = c("tidyverse", "magrittr", "haven", "data.table", "labelled", "here", "stringr", "rlang", "car",
         "caret", "DescTools", "stargazer", "kableExtra", "janitor")
have = want %in% rownames(installed.packages())
if ( any(!have) ) { install.packages( want[!have] ) }
junk <- lapply(want, library, character.only = TRUE)
options(scipen = 99)

rm(list = ls())

# Source the general workflow # ========================================================================

source(here('Scripts', 'synteval_scripts', 'Synteval_gen.R'))


# Country-spec workflow # ==============================================================================

cntry = 'CY'

EES2019_cy <- EES2019 %>% filter(countryshort==cntry)
EES2019_stckd_cy <- EES2019_stckd %>% filter(countryshort==cntry)
EES2019_cdbk_cy <- EES2019_cdbk %>% filter(countryshort==cntry)

rm(cntry)

# Generic dichotomous variables estimation # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

EES2019_cy_stack <- 
  cbind(EES2019_stckd_cy,  
        lapply(data = EES2019_stckd_cy, 
               X = list('Q2', 'Q7', 'Q9_rec', 'Q25_rec'),
               stack_var = 'party',
               FUN = gendic.fun) %>% 
          do.call('cbind',.)) %>% 
  as_tibble()

# Generic distance/proximity variables estimation # - - - - - - - - - - - - - - - - - - - - - - - - - - 

EES2019_cy_stack %<>%
  cbind(.,
        lapply(data = EES2019_cy,
               cdbk = EES2019_cdbk_cy,
               stack = EES2019_cy_stack, 
               crit = 'average',
               rescale = T,
               check = F,
               keep_id = F,
               X = list('Q10','Q11','Q23'),
               FUN = gendis.fun) %>% 
          do.call('cbind',.)) %>% 
  as_tibble()


# Syntvars evaluation: Functions, variables and data frames # ==========================================

# Source auxiliary functions # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

source(here('Scripts', 'synteval_scripts', 'Synteval_auxfuns.R'))

# Country-specific data frames # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

csdf_lst <- list('std'  = EES2019_cy,
                 'cdbk' = EES2019_cdbk_cy,
                 'SDM'  = EES2019_cy_stack)


# Synthetic variables estimation variables # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

syntvars_vrbls <- list('dep'   = list('OLS'     = 'Q10_gen', 
                                      'logit'   = 'Q7_gen'),
                       'indep' = list('ctgrcl' = c('D3_rec', 'D8_rec',  'D5_rec', 'EDU_rec', 
                                                   'D1_rec', 'D7_rec', 'D6_une'),
                                      'cntns'  =  c('D4_age', 'D10_rec')))


# Synthetic variables estimation data frames # - - - - - - - - - - - - - - - - - - - - - - - - - - - - -


regdf_lst  <- list('OLS'   = regdf.auxfun(data        = csdf_lst$SDM,
                                          depvar      = syntvars_vrbls$dep$OLS,
                                          cat.indvar  = syntvars_vrbls$indep$ctgrcl, 
                                          cont.indvar = syntvars_vrbls$indep$cntns),
                   'logit' = regdf.auxfun(data        = csdf_lst$SDM,
                                          depvar      = syntvars_vrbls$dep$logit,
                                          cat.indvar  = syntvars_vrbls$indep$ctgrcl, 
                                          cont.indvar = syntvars_vrbls$indep$cntns))


# Relevant parties data frame # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

relprty_df <- 
  tibble('depvar'    = 
           lapply(1:length(regdf_lst$OLS), function(x){names(regdf_lst$OLS[[x]]) %>% .[2]}) %>% 
           unlist,
         'partycode' =
           lapply(1:length(regdf_lst$OLS), function(x){names(regdf_lst$OLS[[x]]) %>% .[2]}) %>% 
           unlist %>% 
           gsub('stack_','',.) %>% 
           as.numeric)  

relprty_df %<>% 
  mutate('partyname_eng' = 
           csdf_lst$cdbk %>% 
           dplyr::select(partyname_eng, Q7) %>% 
           filter(Q7 %in% relprty_df[['partycode']]) %>% 
           .[['partyname_eng']])



# Syntvars evaluation: Null and full regression models # ===============================================

set.seed(123)

fullmod_lst <- list('OLS'   = gensyn.fun(data        = csdf_lst$SDM,
                                         depvar      = syntvars_vrbls$dep$OLS,
                                         cat.indvar  = syntvars_vrbls$indep$ctgrcl, 
                                         cont.indvar = syntvars_vrbls$indep$cntns,
                                         yhat.name   = 'socdem_synt',
                                         regsum      = T),
                    'logit' = gensyn.fun(data        = csdf_lst$SDM,
                                         depvar      = syntvars_vrbls$dep$logit,
                                         cat.indvar  = syntvars_vrbls$indep$ctgrcl, 
                                         cont.indvar = syntvars_vrbls$indep$cntns,
                                         yhat.name   = 'socdem_synt',
                                         regsum      = T))

nullmod_lst <- list('OLS'   = lapply(X = regdf_lst$OLS,   regmod = 'OLS',   null_mod.auxfun),
                    'logit' = lapply(X = regdf_lst$logit, regmod = 'logit', null_mod.auxfun))


# fullmod_lst$OLS %>% lapply(.,summary)
# fullmod_lst$logit %>% lapply(.,summary)  

# Syntvars evaluation: OLS models summary # ============================================================

# stargazer::stargazer(fullmod_lst$OLS, type = 'text',
#                      column.labels = as.character(relprty_df$Q7),
#                      dep.var.labels = 'PTV',
#                      star.cutoffs = c(0.05, 0.01, 0.001),
#                      omit.stat=c("f", "ser"),
#                      header = F,
#                      style = 'ajps')

# Syntvars evaluation: logit models summary # ==========================================================

# stargazer::stargazer(fullmod_lst$logit, type = 'text',
#                      column.labels = as.character(relprty_df$Q7),
#                      dep.var.labels = 'Vote choice',
#                      star.cutoffs = c(0.05, 0.01, 0.001),
#                      omit.stat=c("f", "ser"),
#                      header = F,
#                      style = 'ajps')

# Syntvars evaluation: OLS models fit stats # ==========================================================

# RMSE and Rsq # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -


ols_df <- 
  tibble(
    'depvar'  = lapply(1:length(regdf_lst$OLS), 
                       function(x){
                         names(regdf_lst$OLS[[x]]) %>% .[2]
                       }) %>% unlist,
    'model'   = rep('full',length(regdf_lst$OLS)),
    'Rsq'     = lapply(1:length(fullmod_lst$OLS),
                       function(x) {
                         fullmod_lst$OLS[[x]] %>% summary %>% .$r.squared %>% round(., 3)
                       }) %>% unlist,
    'Adj_Rsq' = lapply(1:length(fullmod_lst$OLS),
                       function(x) {
                         fullmod_lst$OLS[[x]] %>% summary %>% .$adj.r.squared %>% round(., 3)
                       }) %>% unlist,
    'AIC'     = lapply(1:length(fullmod_lst$OLS),
                       function(x) {
                         fullmod_lst$OLS[[x]] %>% AIC
                       }) %>% unlist) %>% 
  rbind(.,
        tibble(
          'depvar'  = lapply(1:length(regdf_lst$OLS), 
                             function(x){
                               names(regdf_lst$OLS[[x]]) %>% .[2]
                             }) %>% unlist,
          'model'   = rep('null',length(regdf_lst$OLS)),
          'Rsq'     = lapply(1:length(nullmod_lst$OLS),
                             function(x) {
                               nullmod_lst$OLS[[x]] %>% summary %>% .$r.squared %>% round(., 3)
                             }) %>% unlist,
          'Adj_Rsq' = lapply(1:length(nullmod_lst$OLS),
                             function(x) {
                               nullmod_lst$OLS[[x]] %>% summary %>% .$adj.r.squared %>% round(., 3)
                             }) %>% unlist,
          'AIC'     = lapply(1:length(fullmod_lst$OLS),
                             function(x) {
                               nullmod_lst$OLS[[x]] %>% AIC
                             }) %>% unlist))

ols_df %<>% 
  left_join(., relprty_df, by='depvar') %>% 
  dplyr::select(depvar, partycode, partyname_eng, model,
                Rsq, Adj_Rsq, AIC)



# Syntvars evaluation: logit models fit stats # ========================================================


fulllogit_df <- 
  tibble(
    'depvar'     = lapply(1:length(regdf_lst$logit), 
                          function(x){
                            names(regdf_lst$OLS[[x]]) %>% .[2]
                          }) %>% unlist,
    'model'      = rep('full',length(regdf_lst$logit)),
    'Ps_Rsq'     = lapply(1:length(fullmod_lst$logit),
                          function(x){
                            DescTools::PseudoR2(fullmod_lst$logit[[x]], which = 'McFadden')
                          }) %>% unlist,
    'Adj_Ps_Rsq' = lapply(1:length(fullmod_lst$logit),
                          function(x){
                            DescTools::PseudoR2(fullmod_lst$logit[[x]], which = 'McFaddenAdj')
                          }) %>% unlist,
    'AIC'        = lapply(1:length(fullmod_lst$logit),
                          function(x) {
                            fullmod_lst$logit[[x]] %>% AIC
                          }) %>% unlist
  ) %>% 
  left_join(., relprty_df, by='depvar') %>% 
  dplyr::select(depvar, partycode, partyname_eng, model,
                Ps_Rsq, Adj_Ps_Rsq, AIC)



nulllogit_df<- 
  tibble(
    'depvar'     = lapply(1:length(regdf_lst$logit), 
                          function(x){
                            names(regdf_lst$OLS[[x]]) %>% .[2]
                          }) %>% unlist,
    'model'      = rep('null',length(regdf_lst$logit)),
    'Ps_Rsq'     = lapply(1:length(nullmod_lst$logit),
                          function(x){
                            DescTools::PseudoR2(nullmod_lst$logit[[x]], which = 'McFadden')
                          }) %>% unlist,
    'Adj_Ps_Rsq' = lapply(1:length(nullmod_lst$logit),
                          function(x){
                            DescTools::PseudoR2(nullmod_lst$logit[[x]], which = 'McFaddenAdj')
                          }) %>% unlist,
    'AIC'        = lapply(1:length(fullmod_lst$logit),
                          function(x) {
                            nullmod_lst$logit[[x]] %>% AIC
                          }) %>% unlist
  ) %>% 
  left_join(., relprty_df, by='depvar') %>% 
  dplyr::select(depvar, partycode, partyname_eng, model,
                Ps_Rsq, Adj_Ps_Rsq, AIC)



```


# Introduction 

The second part of the evaluation of synthetic variables estimation consists in creating a set of 
summary documents that will part of an appendix to the SDM codebook. These documents will be created 
with `r-markdown` and related packages (e.g. `bookdown`, `knitr`, `kableExtra`) using the information 
collected in our previous step. 

The creation of documents summarizing synthetic variables estimation is needed for transparency and 
reproducibility sake. Synthetic variables are the only variables of the SDM created with procedures that 
bo beyond basic transformations of existing variables. Hence, we must provide a summary of the 
statistical models to the prospective SDM users, including workarounds for solving some issues faced in 
estimating our synthetic variables. 

# Reviewing and summarizing our evaluation scripts, selecting relevant information

The first step for creating our summary documents consists in determining which information should be 
included. As you saw during the last two weeks, the existing evaluation scripts provide a lot of 
information. However, some of them are actually not needed for our documents. For instance, if partial 
models are needed just to deal with 'problematic' models, then creating partial models for *all* the 
regression models that have been estimated, and moreover adding their fit statistics to our summary data
frames, is a useless exercise. This situation was created primarily because the 
evaluation procedure was conceived when the structure of the summary was still under-development (and, 
actually, the evaluation procedure needed also some improvements). 

Thus, now that the structure of the summary documents reached an almost definitive form, the workflow 
used for evaluating synthetic variables estimation must be improved in order to become less redundant, 
clearer and more concise^[I already reviewed our 'synteval' scrit this issue, by removing from each
country-specific 'synteval' script the general workflow used for creating the SDM (namely, a partial 
version of `EES2019_stack.R`). This will return to be very useful for processing our `r-markdown` files 
since they are meant to include more than one country.]. After these improvements, we will include the 
scripts in our `r-markdown` documents and this will allow us to *remove* the evaluation scripts, and 
tidy up our repositories.

To exemplify how we should review our scripts I will make again reference to the one dedicated to the 
Cypriot sample (`EES2019_cy_synteval.R` in the `~/Scripts/synt_eval_scripts/country_spec_scripts/` 
subdirectory). 

## What has to be changed

Overall, the scripts are fine until the sections dedicated to the model fit stats. Thus we run the 
country-specific workflow for creating the other generic variables, then we source the functions, create 
the variables and data frames needed for our evaluations, fit the full and null models, and finally 
summarize them with regression tables and data frames dedicated to model fit statistics. However note 
that an **additional variable** has to be included in our regression models, that is the `D6_une` 
variable (a dichotomous variable that has value 0 for respondents having an employment and 1 for 
unemployed respondents). 

These steps already create more information than what we might actually need in our documents. For 
instance what is definitely needed is the data frame with information concerning the relevant parties (
the `relprty_df` object) and the `stargazer` regression tables. What we do not really need for our 
documents, are the data frames with the fit statistics about the full and null models. Nonetheless, it 
would be wise to leave them in our scripts if we decide, later on, to include them in our scripts or at 
least include some of the information included in those data frames. 

What must be changed is the **estimation and evaluation of the partial models** used for dealing with 
our full models showing inflated standar errors. During the last weeks I realised that we definitely do 
not need to create said constrained models (and, thus, a summary of them) for those full models showing 
reliable estimates. Thus we can implement said sections of our 'synteval' scripts removing some steps, 
and changing others. 

First, after the last section dedicated to full and null models fit statistics 
('*Syntvars evaluation: logit models fit stats*') I would insert a brief comment section. All of us put 
comments on our scripts, and this is very good, but I would like to 'standardize' them. 
My idea is that the first comment section should be like the following one:

```{r, eval=F, echo=T}

# Full models evaluation # ============================================================= #

# logit models 3, 5, and 6 show inflated SE on some predictors, more specifically: 
# Model 3: D7_rec (only for category 2)
# Model 5: D8_rec, D5_rec, EDU_rec, D7_rec (only for category 2), D6_une
# Model 6: D6_une

# Model 3 and 6 constant terms are not affected by D7_rec and D6_une inflated SE, whereas 
# Model 6  constant is affected showing unusual values. We deal only with model 6 affected 
# by separation issue.

```

The we crosstab the dependent variable with the problematic predictors. I realized that the former 
ad hoc function that I created for this purpose was neither appropriate for our tasks nor proper for 
being, then, included in our documents. Thus I created another one^[The function is called `tab.auxfun` 
and takes the following arguments: `data` that should be one of our standard data frames for the 
regression models; `y` that is our dependent variable (character); `x` the predictor of interest 
(character); `na` whether the function should include also missing values (logical, default `TRUE`); 
`perc` whether you want also the percentages values for the cells along with the absolute frequencies 
(logical, default `FALSE`); `which_perc` if included, whether the percentages should be computed 
considering `all` the cells, `rows` or `columns` (character, default `all`).] that is more specific and 
creates tables that, later, can be easily included in our `r-markdown` docs. 

This is the exemplary routine for creating our crosstabs, plus comments about them :

```{r, eval=F, echo=T}

# Syntvars evaluation: evaluating the source of misfit # =============================== #

# Model 5 # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -#

mdl  <- 5
df   <- regdf_lst$logit[[mdl]]
cols <- c('D8_rec', 'D5_rec', 'EDU_rec', 'D7_rec', 'D1_rec', 'D6_une')

tabs <- lapply(data=df, y='stack_505', na=F, X = cols, FUN = tab.auxfun)

# No respondents from rural areas, not married or in partnership, with low education, 
# with high subjective social status, members of trade unions, and unemployed did vote 
# for party 505 (voted by only 5 respondents of the Cypriot sample).


```

After this step, then, we implement our constrained model and we evaluate them against our full models 
using the LR test strategy, performed using the `anova` base function, then commenting the results: 

```{r, eval=F, echo=T}

# Syntvars evaluation: partial logit models # ========================================== #

# Get the df for and estimate the partial models # - - - - - - - - - - - - - - - - - - - #

vrbls_2_drop <- c('D5_rec', 'D8_rec', 'EDU_rec', 'D1_rec', 'D7_rec', 'D6_une')

regdf_lst_part <- 
  regdf_lst$logit %>% 
  lapply(., function(x){
    x %<>% na.omit() %>% dplyr::select(-c(all_of(vrbls_2_drop)))
    }) 

partmod_lst <- 
  lapply(regdf_lst_part, function(x){
    y    <- names(x)[startsWith(names(x), 'stack')]
    xs   <- names(x)[3:length(x)]
    frml <- paste(y, paste0(xs, collapse = ' + '), sep = " ~ ") %>% as.formula
    
    fit <- glm(data = x, formula = frml, family = binomial)
    
    return(fit)
  })

# LR test (Chisq) # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -#

mdls <- c(5)

anova_lst <- 
  anova.auxfun(mdl_lst1 = partmod_lst[c(mdls)],
               mdl_lst2 = fullmod_lst$logit[c(mdls)],
               table = F)

# According to the LR test for Model 5 we cannot reject H0. 

```

After this passage we include the partial model in a final list of models of interest, with a new 
summary of regression estimates using the `stargazer` package: 

```{r, eval=F, echo=T}

# Syntvars evaluation: logit models summary # ========================================== # 

# fullmod_lst$logit[c(mdls)] <- partmod_lst[c(mdls)]

finalmod_lst <- list()
finalmod_lst[['OLS']] <- fullmod_lst[['OLS']]
for(i in 1:length(fullmod_lst[['logit']])) {
  finalmod_lst[['logit']][[i]] <- fullmod_lst[['logit']][[i]]
  
  if (i %in% mdls) {
    finalmod_lst[['logit']][[i]] <- partmod_lst[[mdls]]
  }
}
rm(i)

# stargazer::stargazer(finalmod_lst$logit, type = 'text',
#                      column.labels = as.character(relprty_df$partycode),
#                      dep.var.labels = c('', '', ''),
#                      star.cutoffs = c(0.05, 0.01, 0.001),
#                      omit.stat=c("f", "ser"),
#                      header = F,
#                      style = 'ajps')

```

Again, once finished the evaluation, we must modify our 'genvars' country-specific scripts accordingly. 
Remember that we have a new variable to be included, thus we need to modify such scripts even if no 
issues are found. The following step, then, is dedicated to the creation of the `r-markdown` scripts. 

## Summarizing evaluations with an `r-markdown` script

For creating our `r-markdown` scripts we move then to the `~/Docs/Synteval/scripts` subdirectory. Here 
you can find the exemplary script `EES2019_synteval_gc.Rmd`, with '`gc`' referring to my name and 
surname first letters. This script *is not* country specific, but rather is conceived for including a 
summary of the evaluation of synthetic variables estimation of all the countries that each of us 
analysed during the last few weeks. This will allow us, later on, to create a single `r-markdown` script
formatted as a pdf document. 

Let's turn to the script. First the `YAML` header. You can copy-paste it from the exemplary script, and 
then modify the `title`, `subtitle`, `author`, and `date` arguments. 

```
---
title: EES2019 Stacking Process 
subtitle: Synthetic Variables Evaluation (Pt.2)
author: Giuseppe Carteny
date: 24.10.2021 
toc: true
output: 
  bookdown::pdf_document2:
    includes:
      in_header: First_steps_header.tex
urlcolor: RedOrange
--- 
```


Second, there's the first chunk of 
code that can be plainly copy-pasted from the exemplary script, since it just load (and eventually 
install) the packages that are needed, then sourcing the (partial) general workflow needed for our 
evaluations. 








